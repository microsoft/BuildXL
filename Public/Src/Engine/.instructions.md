# Engine Component

The Engine is BuildXL's core execution and orchestration layer. It manages the pip graph, schedules execution with sandboxing, implements caching and distribution, and coordinates work across local and distributed machines.

## Architecture

### Two Build Phases
1. **Graph Construction**: Frontends evaluate specs → pip graph (cacheable)
2. **Execution**: Scheduler runs pips in dependency order → cache check → sandbox execution → cache store

### Cache Lookup Flow
```
Per pip:
  1. Compute weak fingerprint (static inputs) → cache lookup
  2. Weak hit → compute strong fingerprint (+ observed accesses) → strong lookup
  3. Strong hit → deploy from cache
  4. Miss at any level → execute in sandbox → store to cache
```

### Distributed Build Flow
- **Orchestrator**: Constructs pip graph, schedules work, sends pips via gRPC
- **Workers**: Receive graph hashes, reconstruct graph, execute assigned pips, upload outputs to cache
- **Constraint**: MaterializeInputs, ExecuteProcess, and PostProcess must run on the same worker
- Workers can retry failed pips on another worker (`/numRetryFailedPipsOnAnotherWorker`)

## Module Structure

| Directory | Purpose |
|-----------|---------|
| `Dll/` | Engine initialization, graph construction, orchestration (`Engine.cs`, `CacheInitializer.cs`, `MountsTable.cs`) |
| `Scheduler/` | Core execution scheduling (`Scheduler.cs`, `PipExecutor.cs`, `PipQueue.cs`) |
| `Scheduler/Distribution/` | Distributed build coordination (`OrchestratorService.cs`, `WorkerService.cs`, gRPC) |
| `Scheduler/Caching/` | Cache lookup and fingerprinting logic |
| `Scheduler/IncrementalScheduling/` | USN-based incremental scheduling |
| `Processes/` | Sandboxed process execution (`SandboxedProcess.cs`, `FileAccessManifest.cs`) |
| `Processes/Sideband/` | Out-of-process file access observations |
| `Cache/` | Engine-level cache management, fingerprints, serialization |
| `Cache.Plugin.CacheCore/` | Cache plugin for CacheCore integration |
| `Distribution.Grpc/` | gRPC transport for distributed builds |
| `ProcessPipExecutor/` | Process pip execution logic |
| `ViewModel/` | Build visualization data model |
| `UnitTests/` | Engine unit and integration tests |

## Key Types

### Execution
- `Scheduler` — Main orchestrator of pip execution
- `PipExecutor` — Executes individual pip steps (CacheLookup, MaterializeInputs, ExecuteProcess, PostProcess)
- `PipQueue` — Manages ready-to-run pips across dispatcher queues (CPU, CacheLookup, IO, Materialize)
- `SandboxedProcess` — Wraps process execution with file-access monitoring

### Caching
- `WeakFingerprint` / `StrongFingerprint` — Multi-level cache keys
- `ContentFingerprint` — Hash of file/directory content
- `DirectoryFingerprint` — Hash of directory membership for enumeration stability

### Distribution
- `OrchestratorService` / `WorkerService` — gRPC-based coordination
- `RemoteWorker` — Scheduler's handle to a remote execution machine

## Key Flags

### Scheduler & Concurrency
| Flag | Purpose |
|------|---------|
| `/maxProc` | Max concurrent processes (default: 90% of CPU count) |
| `/maxIO` | Max concurrent I/O operations |
| `/maxCacheLookup` | Max concurrent cache lookups |
| `/maxRamUtilizationPercentage` | Memory throttle (default: 90%) |
| `/manageMemoryMode` | Memory strategy: CancellationRam, EmptyWorkingSet, Suspend |

### Caching & Graph
| Flag | Purpose |
|------|---------|
| `/cacheGraph` | Cache pip graph between runs |
| `/incrementalScheduling+` | Enable USN-based pip pruning (local builds only) |
| `/enableLazyOutputs` | Lazily materialize cache hits |
| `/cacheMiss` | Enable runtime cache miss analysis |
| `/cacheMiss+` | Auto-select cache miss baseline (Azure DevOps heuristic: current branch → PR source → PR target) |
| `/cacheMissDiffFormat` | CustomJsonDiff (default) or JsonDiffPatch |
| `/pathSetThreshold` | Weak fingerprint augmentation trigger (default: 5 pathsets) |
| `/delayCacheLookupMin/Max` | Throttle cache lookups for convergence (tighten lookup-to-execution window) |
| `/storeFingerprints` | Persist fingerprint computations |

### Distribution
| Flag | Purpose |
|------|---------|
| `/distributedBuildRole` | Orchestrator, Worker, or None |
| `/distributedBuildServicePort` | Local gRPC service port |
| `/distributedBuildWorker` | Remote worker address:port |
| `/numRetryFailedPipsOnAnotherWorker` | Retry count on worker failure |

## Advanced Features

### Incremental Scheduling (`/incrementalScheduling+`)
Tracks USN records of input/output files. On next build, compares current USN with recorded — skips clean pips. **Incompatible** with distributed builds, shared opaque directories, and lazy outputs.

### Server Mode (`/server+`, default on Windows)
Keeps bxl.exe process alive between builds for fast iteration. 60-minute idle timeout. Creates a deployment copy of the engine binaries.

### Graph Reuse
1. Check engine cache with USN-based staleness detection
2. Fall back to remote cache lookup by (weak fingerprint, inputs hash)
3. Fall back to full graph construction

### Cache Miss Analysis
- `/cacheMiss` enables runtime analysis — compares against last execution, outputs `BuildXL.CacheMiss.log`
- FingerprintStore: persistent database of fingerprint data, stored in content cache for cross-build reuse
- Postmortem: `bxl /m:CacheMiss` (works with incremental scheduling) or `bxl /m:CacheMissLegacy` (compares two full builds)
- Requires same graph scope between compared builds — filtered builds may produce inaccurate diffs

### On-Demand Materialization API
IPC-based API for external processes to request file materialization at runtime:
```typescript
Artifact.fileId(file: File): string                    // Get BuildXL file identifier
Transformer.getIpcServerMoniker(): IpcMoniker          // Get IPC endpoint
// External process calls: MaterializeFile(fileId) → returns disk path
```
Used by DropDaemon to avoid eagerly materializing files that only need hash-based association.

### Memory Management
Scheduler queues: CacheLookup, CPU (default 90% cores), IO (100% cores), Materialize (100% cores). Under memory pressure, the engine can cancel, empty working sets, or suspend processes based on `/manageMemoryMode`.

## Testing

```bash
# Build and test the engine
bxl IntegrationTest.BuildXL.Scheduler.dsc

# Specific test class
bxl IntegrationTest.BuildXL.Scheduler.dsc -TestClass IntegrationTest.BuildXL.Scheduler.BaselineTests

# Specific test method
bxl IntegrationTest.BuildXL.Scheduler.dsc -TestMethod IntegrationTest.BuildXL.Scheduler.BaselineTests.VerifyGracefulTeardownOnPipFailure
```

## Key Log Files
- `BuildXL.log` — Main execution log with critical path analysis
- `BuildXL.status.csv` — Machine performance counters every 2 seconds
- `BuildXL.DistributionRpc.log` — gRPC activity for distributed builds
- `BuildXL.xlg` — Binary execution log with detailed events

## Common Pitfalls
- **Cache key changes** invalidate all existing caches — coordinate broadly
- **Fingerprinting changes** affect cache validity — test with local cache first
- **Incremental scheduling** is incompatible with distributed builds and shared opaques
- **Sandbox changes** must be tested on both Windows (Detours) and Linux (ptrace/eBPF)
